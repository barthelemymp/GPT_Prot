{
    "num_encoder_layers": 2,
    "num_decoder_layers": 2,
    "batch_size": 32,
    "num_heads": 1,
    "forward_expansion": 2048,
    "Align": true,
    "num_epochs": 5000,
    "wd": 0.0,
    "trg_vocab_size": 25,
    "embedding_size": 55,
    "learning_rate": 5e-05,
    "dropout": 0.1
}